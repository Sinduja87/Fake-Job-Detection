{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Logistic Regression model with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaiganeshkannan/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/jaiganeshkannan/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.bagging module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/jaiganeshkannan/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/jaiganeshkannan/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/jaiganeshkannan/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/jaiganeshkannan/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import string\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us load the dataset and check the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>country</th>\n",
       "      <th>has_company_logo</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>required_experience</th>\n",
       "      <th>required_education</th>\n",
       "      <th>function</th>\n",
       "      <th>fraudulent</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>Other</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>0</td>\n",
       "      <td>Marketing Intern We're Food52, and we've creat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NZ</td>\n",
       "      <td>1</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>0</td>\n",
       "      <td>Customer Service - Cloud Video Production 90 S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>Other</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>Commissioning Machinery Assistant (CMA) Valor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Sales</td>\n",
       "      <td>0</td>\n",
       "      <td>Account Executive - Washington DC Our passion ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Health Care Provider</td>\n",
       "      <td>0</td>\n",
       "      <td>Bill Review Manager SpotSource Solutions LLC i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 country  has_company_logo employment_type required_experience  \\\n",
       "0           0      US                 1           Other          Internship   \n",
       "1           1      NZ                 1       Full-time      Not Applicable   \n",
       "2           2      US                 1           Other      Not Applicable   \n",
       "3           3      US                 1       Full-time    Mid-Senior level   \n",
       "4           4      US                 1       Full-time    Mid-Senior level   \n",
       "\n",
       "  required_education              function  fraudulent  \\\n",
       "0        Unspecified             Marketing           0   \n",
       "1        Unspecified      Customer Service           0   \n",
       "2        Unspecified                 Other           0   \n",
       "3  Bachelor's Degree                 Sales           0   \n",
       "4  Bachelor's Degree  Health Care Provider           0   \n",
       "\n",
       "                                                text  \n",
       "0  Marketing Intern We're Food52, and we've creat...  \n",
       "1  Customer Service - Cloud Video Production 90 S...  \n",
       "2  Commissioning Machinery Assistant (CMA) Valor ...  \n",
       "3  Account Executive - Washington DC Our passion ...  \n",
       "4  Bill Review Manager SpotSource Solutions LLC i...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the data\n",
    "df = pd.read_csv('Data/fake_job_posting_clean.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will drop the 'Unnamed :0' index column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Removing the index column\n",
    "df.drop('Unnamed: 0', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now split the dataset into training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Test Split of data\n",
    "X = df.drop('fraudulent', axis =1)\n",
    "y = df['fraudulent']\n",
    "\n",
    "X_train,X_test, y_train,y_test = train_test_split(X,y,test_size = 0.20, stratify = y, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index of the train and test dataset are reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Resetting the index the test and train data\n",
    "X_train = X_train.reset_index(drop = True)\n",
    "y_train = y_train.reset_index(drop = True)\n",
    "X_test = X_test.reset_index(drop = True)\n",
    "y_test = y_test.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categorical variable are takeninto a separate dataframe and using onehot encoder all the categorical features are coverted in dummy variables in the column transformer function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ohe = X_train.drop(columns = ['has_company_logo', 'text'], axis = 1)\n",
    "X_test_ohe = X_test.drop(columns = ['has_company_logo', 'text'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>required_experience</th>\n",
       "      <th>required_education</th>\n",
       "      <th>function</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Associate</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Information Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>Part-time</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Customer Service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GB</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Associate</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Sales</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country employment_type required_experience required_education  \\\n",
       "0      US       Full-time           Associate  Bachelor's Degree   \n",
       "1      US       Full-time      Not Applicable        Unspecified   \n",
       "2      CA       Full-time      Not Applicable        Unspecified   \n",
       "3      US       Part-time      Not Applicable        Unspecified   \n",
       "4      GB       Full-time           Associate  Bachelor's Degree   \n",
       "\n",
       "                 function  \n",
       "0               Marketing  \n",
       "1                   Other  \n",
       "2  Information Technology  \n",
       "3        Customer Service  \n",
       "4                   Sales  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_ohe.head()\n",
    "X_test_ohe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_transform = [('OHE_transform', OneHotEncoder(handle_unknown = 'ignore'), ['country',\n",
    "                                                                              'employment_type',\n",
    "                                                                              'required_education',\n",
    "                                                                              'required_experience',\n",
    "                                                                              'function'])]\n",
    "col_trans = ColumnTransformer(col_transform)\n",
    "col_trans.fit(X_train_ohe)\n",
    "X_train_e = col_trans.transform(X_train_ohe)\n",
    "X_test_e = col_trans.transform(X_test_ohe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column transformer returned as a sparse matrix and hence converting the array into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Converting the one hot encoded array to a dataframe\n",
    "train_ohe = pd.DataFrame(columns=col_trans.get_feature_names(), data=X_train_e.toarray())\n",
    "test_ohe= pd.DataFrame(columns=col_trans.get_feature_names(), data=X_test_e.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did during the modelling, the tokenniser is defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jaiganeshkannan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "ENGLISH_STOP_WORDS = stopwords.words('english')\n",
    "\n",
    "def my_tokenizer(sentence):\n",
    "    \n",
    "    for punctuation_mark in string.punctuation:\n",
    "        # Remove punctuation and set to lower case\n",
    "        sentence = sentence.replace(punctuation_mark,'').lower()\n",
    "\n",
    "    # split sentence into words\n",
    "    listofwords = sentence.split(' ')\n",
    "    listofstemmed_words = []\n",
    "    \n",
    "        \n",
    "    # Remove stopwords and any tokens that are just empty strings\n",
    "    for word in listofwords:\n",
    "        if (not word in ENGLISH_STOP_WORDS) and (word!=''):\n",
    "            # Stem words\n",
    "            stemmed_word = stemmer.stem(word)\n",
    "            listofstemmed_words.append(stemmed_word)\n",
    "\n",
    "    return listofstemmed_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text columns is stored ina separate dataframe to convert it into token using TF-IDF vectoriser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t = X_train['text']\n",
    "X_test_t = X_test['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaiganeshkannan/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "##Creating a sparse matrix for text\n",
    "text = TfidfVectorizer(min_df=20, tokenizer=my_tokenizer, ngram_range = (1,3))\n",
    "text.fit(X_train_t)\n",
    "X_train_t = text.transform(X_train_t)\n",
    "X_test_t = text.transform(X_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Converting the array to a dataframe\n",
    "train_t = pd.DataFrame(columns=text.get_feature_names(), data=X_train_t.toarray())\n",
    "test_t= pd.DataFrame(columns=text.get_feature_names(), data=X_test_t.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now concatinate the onehotencoded dataframe and vectorised token dataframe with the original dataframe. We willthen drop the original columns that are transformed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining the dataset, on=hehotencoded dataset and vectorised dataset\n",
    "X_train_ct = pd.concat([X_train,train_t,train_ohe], axis = 1)\n",
    "X_test_ct = pd.concat([X_test,test_t,test_ohe], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the dupliated columns\n",
    "X_train_ct.drop(columns = ['text','country','employment_type','required_education',\n",
    "                           'required_experience','function'] , axis=1, inplace = True)\n",
    "X_test_ct.drop(columns = ['text','country','employment_type','required_education',\n",
    "                           'required_experience','function'] , axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now over sample the train data using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaiganeshkannan/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# instantiate SMOTE\n",
    "sm = SMOTE(sampling_strategy = 0.3, random_state = 1)\n",
    "\n",
    "# performing the SMOTE oversampling\n",
    "X_train_sm, y_train_sm = sm.fit_resample(X_train_ct, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression model is run with the hyper parameter values from th ebest estimator identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.46 s, sys: 1.36 s, total: 7.82 s\n",
      "Wall time: 6.73 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=10, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#Instantiate the model\n",
    "lg_s_model = LogisticRegression(solver = 'liblinear', C=0.5, penalty = 'l2', random_state = 10)\n",
    "#Fit the model\n",
    "lg_s_model.fit(X_train_sm, y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9792613636363636\n",
      "0.9803583735354927\n"
     ]
    }
   ],
   "source": [
    "#scoring the model\n",
    "print(lg_s_model.score(X_test_ct, y_test))\n",
    "print(lg_s_model.score(X_train_sm, y_train_sm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now retrieve the positive and the negative coeffients using `.coef_`and iterpret it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Storing the coefficients to a dataframe\n",
    "coeff = pd.DataFrame(lg_s_model.coef_, columns = X_train_ct.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transposing the coefficients\n",
    "coeff_col = coeff.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>has_company_logo</th>\n",
       "      <td>-2.092332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OHE_transform__x4_Health Care Provider</th>\n",
       "      <td>-1.928840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OHE_transform__x0_GR</th>\n",
       "      <td>-1.671207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team</th>\n",
       "      <td>-1.668670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OHE_transform__x1_Temporary</th>\n",
       "      <td>-1.618331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               0\n",
       "has_company_logo                       -2.092332\n",
       "OHE_transform__x4_Health Care Provider -1.928840\n",
       "OHE_transform__x0_GR                   -1.671207\n",
       "team                                   -1.668670\n",
       "OHE_transform__x1_Temporary            -1.618331"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Identifying the top 5 negative coefficients\n",
    "coeff_col.sort_values(by = [0], ascending=True).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>unkc</th>\n",
       "      <td>3.221086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earn</th>\n",
       "      <td>3.164142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>money</th>\n",
       "      <td>2.639044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OHE_transform__x0_MY</th>\n",
       "      <td>2.448140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>assist</th>\n",
       "      <td>2.172617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0\n",
       "unkc                  3.221086\n",
       "earn                  3.164142\n",
       "money                 2.639044\n",
       "OHE_transform__x0_MY  2.448140\n",
       "assist                2.172617"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Identifying the top 5 positive coefficients\n",
    "coeff_col.sort_values(by = [0], ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
